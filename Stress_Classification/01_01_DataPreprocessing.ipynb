{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead49057-7b72-457a-91a8-2143398bee76",
   "metadata": {},
   "source": [
    "## Data Formatting\n",
    "- 1분 단위 Signal Segmentation\n",
    "- Stress Class는 0(baseline, amusement, meditation), 1(stress)로 binary classification으로 Formulation\n",
    "- train, val, test split은 각각 10명, 2명, 3명의 Signal record로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d8bbfbd-6d34-4427-9e1b-96f5e0b966cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8505e41f-d155-4c4f-a32a-cfc861bdabbd",
   "metadata": {},
   "source": [
    "- 필요 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d10ea820-b93c-438e-b901-9fe3aa820644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(path):\n",
    "    with open(path,'rb') as file: # Binary read\n",
    "        _data = pickle._Unpickler(file)\n",
    "        _data.encoding = 'latin1'\n",
    "        data = _data.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06196ad7-e827-4753-b0c4-a9d8619a8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_spline(ecg, step=1, k=3):\n",
    "    x_new = np.arange(0, ecg.shape[0], ecg.shape[0]/step)\n",
    "    interp_spline_method = splrep(np.arange(0, ecg.shape[0], 1), ecg, k=k)\n",
    "    \n",
    "    return splev(x_new, interp_spline_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f91bd8d-fb06-4936-83b9-ca89ec31949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(a, w = 4, o = 2, copy = False):\n",
    "    sh = (a.size - w + 1, w)\n",
    "    st = a.strides * 2\n",
    "    view = np.lib.stride_tricks.as_strided(a, strides = st, shape = sh)[0::o]\n",
    "    if copy:\n",
    "        return view.copy()\n",
    "    else:\n",
    "        return view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a256a2-06f5-4dd6-8fa2-904f06698d20",
   "metadata": {},
   "source": [
    "- load subjects lsit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74ddbc9e-aa26-43a9-9493-529ba0c9eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "wesad_subjects = glob.glob('../00_Data/01_PPG2ECG/01_Original/04_WESAD/*')\n",
    "wesad_subjects = [wesad_subjects[i].split('\\\\')[-1] for i in range(len(wesad_subjects))][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5952eb18-3f61-498c-8d2b-7208290c27bf",
   "metadata": {},
   "source": [
    "- train, val, test subject split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d434941-01a5-4120-961a-c7a9e3b1d038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([12, 13, 14]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_idx = np.array([0, 1])\n",
    "test_idx = np.array([12, 13, 14])\n",
    "val_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3006432-0e50-4bfc-8809-876a4691083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_subs = [wesad_subjects[val_idx[i]] for i in range(len(val_idx))]\n",
    "test_subs = [wesad_subjects[test_idx[i]] for i in range(len(test_idx))]\n",
    "train_subs = list(set(wesad_subjects) - set(list(val_subs) + list(test_subs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f06dce-e379-46aa-88cc-eb5d9296f656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['S17', 'S5', 'S3', 'S15', 'S14', 'S16', 'S13', 'S6', 'S4', 'S2'],\n",
       " ['S10', 'S11'],\n",
       " ['S7', 'S8', 'S9'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subs, val_subs, test_subs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660bde24-2605-413b-b2fe-a32c5de3f636",
   "metadata": {},
   "source": [
    "- binary class mapping dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a5334e8-1540-4b6e-87d6-e31a86145133",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cls_map_dict = {}\n",
    "binary_cls_map_dict[1] = 0\n",
    "binary_cls_map_dict[2] = 1\n",
    "binary_cls_map_dict[3] = 0\n",
    "binary_cls_map_dict[4] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da79bac1-0a36-45af-8c62-142be4d379fe",
   "metadata": {},
   "source": [
    "- train dataset binary classification processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ac6e26a-dcbc-446f-a322-a545452b2452",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:39<00:00,  3.98s/it]\n"
     ]
    }
   ],
   "source": [
    "sampling_time = 60\n",
    "overlap_ratio = 0.1\n",
    "save_prefix = '../00_Data/04_Stress_Classification/01_train/'\n",
    "\n",
    "break_idx = 0\n",
    "for train_sub in tqdm(train_subs, total=len(train_subs)):\n",
    "    data_path = '../00_Data/01_PPG2ECG/01_Original/04_WESAD/' + train_sub + '/' + train_sub + '.pkl'\n",
    "    \n",
    "    # load pickle\n",
    "    data_dict = load_pickle(data_path)\n",
    "    \n",
    "    # ecg info\n",
    "    ecg_ori_sig = data_dict['signal']['chest']['ECG']\n",
    "    ecg_sig_fs = 700\n",
    "    \n",
    "    # ppg info\n",
    "    ppg_ori_sig = data_dict['signal']['wrist']['BVP']\n",
    "    ppg_sig_fs = 64\n",
    "    \n",
    "    # label info\n",
    "    label_ori_sig = data_dict['label']\n",
    "    label_sig_fs = 700\n",
    "    \n",
    "    # overlap windowing parameter\n",
    "    ecg_target_frequency = ecg_sig_fs * sampling_time\n",
    "    ecg_overlap_frequency = ecg_target_frequency-round((overlap_ratio * ecg_target_frequency))\n",
    "    \n",
    "    ppg_target_frequency = ppg_sig_fs * sampling_time\n",
    "    ppg_overlap_frequency = ppg_target_frequency-round((overlap_ratio * ppg_target_frequency))\n",
    "    \n",
    "    label_target_frequency = label_sig_fs * sampling_time\n",
    "    label_overlap_frequency = label_target_frequency-round((overlap_ratio * label_target_frequency))\n",
    "    \n",
    "    # windowing\n",
    "    ppg_seg_result = window(a=ppg_ori_sig[:,0], w=ppg_target_frequency, o=ppg_overlap_frequency)\n",
    "    ecg_seg_result = window(a=ecg_ori_sig[:,0], w=ecg_target_frequency, o=ecg_overlap_frequency)\n",
    "    label_seg_result = window(a=label_ori_sig, w=label_target_frequency, o=label_overlap_frequency)\n",
    "    \n",
    "    for i in range(len(ppg_seg_result)):\n",
    "        label_count = pd.Series(label_seg_result[i]).value_counts()\n",
    "        label_index = np.array(label_count.index)\n",
    "        label_count_num = label_count.values\n",
    "        \n",
    "        if len(label_index) == 1:\n",
    "            if label_index == 0 or label_index>=5:\n",
    "                continue    \n",
    "            else:\n",
    "                label = binary_cls_map_dict[label_index[0]]\n",
    "        else:\n",
    "            label_ratio = label_count_num / label_count_num.sum()\n",
    "            label_ratio_sort = np.argsort(label_ratio)[::-1]\n",
    "            major_label = label_index[label_ratio_sort[0]]\n",
    "            \n",
    "            if major_label == 0 or major_label>=5:\n",
    "                continue\n",
    "            else:\n",
    "                label = binary_cls_map_dict[major_label]\n",
    "                \n",
    "        seg_dict = {}\n",
    "        seg_dict['ECG'] = {}\n",
    "        seg_dict['ECG']['sig'] = ecg_seg_result[i]\n",
    "        seg_dict['ECG']['sig_fs'] = ecg_sig_fs\n",
    "        seg_dict['ECG']['sig_time'] = sampling_time\n",
    "        seg_dict['ECG']['sig_len'] = len(ecg_seg_result[i])\n",
    "        seg_dict['ECG']['sig_info'] = 'Single'\n",
    "        seg_dict['ECG']['units'] = None\n",
    "        \n",
    "        seg_dict['PPG'] = {}\n",
    "        seg_dict['PPG']['sig'] = ppg_seg_result[i]\n",
    "        seg_dict['PPG']['sig_fs'] = ppg_sig_fs\n",
    "        seg_dict['PPG']['sig_time'] = sampling_time\n",
    "        seg_dict['PPG']['sig_len'] = len(ppg_seg_result[i])\n",
    "        seg_dict['PPG']['units'] = None\n",
    "        \n",
    "        seg_dict['label'] = label\n",
    "        \n",
    "        save_filename = train_sub + '_' + str(i).zfill(3) + '.npy'\n",
    "        save_path = save_prefix + save_filename\n",
    "        np.save(save_path, seg_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff4b854-6fae-4371-9bbf-b21489d062c6",
   "metadata": {},
   "source": [
    "- val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d80f1eea-35ca-4fba-86e9-4162e4b23f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.49s/it]\n"
     ]
    }
   ],
   "source": [
    "sampling_time = 60\n",
    "overlap_ratio = 0.1\n",
    "save_prefix = '../00_Data/04_Stress_Classification/02_val/'\n",
    "\n",
    "break_idx = 0\n",
    "for val_sub in tqdm(val_subs, total=len(val_subs)):\n",
    "    data_path = '../00_Data/01_PPG2ECG/01_Original/04_WESAD/' + val_sub + '/' + val_sub + '.pkl'\n",
    "    \n",
    "    # load pickle\n",
    "    data_dict = load_pickle(data_path)\n",
    "    \n",
    "    # ecg info\n",
    "    ecg_ori_sig = data_dict['signal']['chest']['ECG']\n",
    "    ecg_sig_fs = 700\n",
    "    \n",
    "    # ppg info\n",
    "    ppg_ori_sig = data_dict['signal']['wrist']['BVP']\n",
    "    ppg_sig_fs = 64\n",
    "    \n",
    "    # label info\n",
    "    label_ori_sig = data_dict['label']\n",
    "    label_sig_fs = 700\n",
    "    \n",
    "    # overlap windowing parameter\n",
    "    ecg_target_frequency = ecg_sig_fs * sampling_time\n",
    "    ecg_overlap_frequency = ecg_target_frequency-round((overlap_ratio * ecg_target_frequency))\n",
    "    \n",
    "    ppg_target_frequency = ppg_sig_fs * sampling_time\n",
    "    ppg_overlap_frequency = ppg_target_frequency-round((overlap_ratio * ppg_target_frequency))\n",
    "    \n",
    "    label_target_frequency = label_sig_fs * sampling_time\n",
    "    label_overlap_frequency = label_target_frequency-round((overlap_ratio * label_target_frequency))\n",
    "    \n",
    "    # windowing\n",
    "    ppg_seg_result = window(a=ppg_ori_sig[:,0], w=ppg_target_frequency, o=ppg_overlap_frequency)\n",
    "    ecg_seg_result = window(a=ecg_ori_sig[:,0], w=ecg_target_frequency, o=ecg_overlap_frequency)\n",
    "    label_seg_result = window(a=label_ori_sig, w=label_target_frequency, o=label_overlap_frequency)\n",
    "    \n",
    "    for i in range(len(ppg_seg_result)):\n",
    "        label_count = pd.Series(label_seg_result[i]).value_counts()\n",
    "        label_index = np.array(label_count.index)\n",
    "        label_count_num = label_count.values\n",
    "        \n",
    "        if len(label_index) == 1:\n",
    "            if label_index == 0 or label_index>=5:\n",
    "                continue    \n",
    "            else:\n",
    "                label = binary_cls_map_dict[label_index[0]]\n",
    "        else:\n",
    "            label_ratio = label_count_num / label_count_num.sum()\n",
    "            label_ratio_sort = np.argsort(label_ratio)[::-1]\n",
    "            major_label = label_index[label_ratio_sort[0]]\n",
    "            \n",
    "            if major_label == 0 or major_label>=5:\n",
    "                continue\n",
    "            else:\n",
    "                label = binary_cls_map_dict[major_label]\n",
    "                \n",
    "        seg_dict = {}\n",
    "        seg_dict['ECG'] = {}\n",
    "        seg_dict['ECG']['sig'] = ecg_seg_result[i]\n",
    "        seg_dict['ECG']['sig_fs'] = ecg_sig_fs\n",
    "        seg_dict['ECG']['sig_time'] = sampling_time\n",
    "        seg_dict['ECG']['sig_len'] = len(ecg_seg_result[i])\n",
    "        seg_dict['ECG']['sig_info'] = 'Single'\n",
    "        seg_dict['ECG']['units'] = None\n",
    "        \n",
    "        seg_dict['PPG'] = {}\n",
    "        seg_dict['PPG']['sig'] = ppg_seg_result[i]\n",
    "        seg_dict['PPG']['sig_fs'] = ppg_sig_fs\n",
    "        seg_dict['PPG']['sig_time'] = sampling_time\n",
    "        seg_dict['PPG']['sig_len'] = len(ppg_seg_result[i])\n",
    "        seg_dict['PPG']['units'] = None\n",
    "        \n",
    "        seg_dict['label'] = label\n",
    "        \n",
    "        save_filename = val_sub + '_' + str(i).zfill(3) + '.npy'\n",
    "        save_path = save_prefix + save_filename\n",
    "        np.save(save_path, seg_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21353d4e-2de0-4191-992e-3d8ac2bb3565",
   "metadata": {},
   "source": [
    "- testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "303b3ff5-499a-4075-b4dc-4280aecc4ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:10<00:00,  3.40s/it]\n"
     ]
    }
   ],
   "source": [
    "sampling_time = 60\n",
    "overlap_ratio = 0.1\n",
    "save_prefix = '../00_Data/04_Stress_Classification/03_test/'\n",
    "\n",
    "break_idx = 0\n",
    "for test_sub in tqdm(test_subs, total=len(test_subs)):\n",
    "    data_path = '../00_Data/01_PPG2ECG/01_Original/04_WESAD/' + test_sub + '/' + test_sub + '.pkl'\n",
    "    \n",
    "    # load pickle\n",
    "    data_dict = load_pickle(data_path)\n",
    "    \n",
    "    # ecg info\n",
    "    ecg_ori_sig = data_dict['signal']['chest']['ECG']\n",
    "    ecg_sig_fs = 700\n",
    "    \n",
    "    # ppg info\n",
    "    ppg_ori_sig = data_dict['signal']['wrist']['BVP']\n",
    "    ppg_sig_fs = 64\n",
    "    \n",
    "    # label info\n",
    "    label_ori_sig = data_dict['label']\n",
    "    label_sig_fs = 700\n",
    "    \n",
    "    # overlap windowing parameter\n",
    "    ecg_target_frequency = ecg_sig_fs * sampling_time\n",
    "    ecg_overlap_frequency = ecg_target_frequency-round((overlap_ratio * ecg_target_frequency))\n",
    "    \n",
    "    ppg_target_frequency = ppg_sig_fs * sampling_time\n",
    "    ppg_overlap_frequency = ppg_target_frequency-round((overlap_ratio * ppg_target_frequency))\n",
    "    \n",
    "    label_target_frequency = label_sig_fs * sampling_time\n",
    "    label_overlap_frequency = label_target_frequency-round((overlap_ratio * label_target_frequency))\n",
    "    \n",
    "    # windowing\n",
    "    ppg_seg_result = window(a=ppg_ori_sig[:,0], w=ppg_target_frequency, o=ppg_overlap_frequency)\n",
    "    ecg_seg_result = window(a=ecg_ori_sig[:,0], w=ecg_target_frequency, o=ecg_overlap_frequency)\n",
    "    label_seg_result = window(a=label_ori_sig, w=label_target_frequency, o=label_overlap_frequency)\n",
    "    \n",
    "    for i in range(len(ppg_seg_result)):\n",
    "        label_count = pd.Series(label_seg_result[i]).value_counts()\n",
    "        label_index = np.array(label_count.index)\n",
    "        label_count_num = label_count.values\n",
    "        \n",
    "        if len(label_index) == 1:\n",
    "            if label_index == 0 or label_index>=5:\n",
    "                continue    \n",
    "            else:\n",
    "                label = binary_cls_map_dict[label_index[0]]\n",
    "        else:\n",
    "            label_ratio = label_count_num / label_count_num.sum()\n",
    "            label_ratio_sort = np.argsort(label_ratio)[::-1]\n",
    "            major_label = label_index[label_ratio_sort[0]]\n",
    "            \n",
    "            if major_label == 0 or major_label>=5:\n",
    "                continue\n",
    "            else:\n",
    "                label = binary_cls_map_dict[major_label]\n",
    "                \n",
    "        seg_dict = {}\n",
    "        seg_dict['ECG'] = {}\n",
    "        seg_dict['ECG']['sig'] = ecg_seg_result[i]\n",
    "        seg_dict['ECG']['sig_fs'] = ecg_sig_fs\n",
    "        seg_dict['ECG']['sig_time'] = sampling_time\n",
    "        seg_dict['ECG']['sig_len'] = len(ecg_seg_result[i])\n",
    "        seg_dict['ECG']['sig_info'] = 'Single'\n",
    "        seg_dict['ECG']['units'] = None\n",
    "        \n",
    "        seg_dict['PPG'] = {}\n",
    "        seg_dict['PPG']['sig'] = ppg_seg_result[i]\n",
    "        seg_dict['PPG']['sig_fs'] = ppg_sig_fs\n",
    "        seg_dict['PPG']['sig_time'] = sampling_time\n",
    "        seg_dict['PPG']['sig_len'] = len(ppg_seg_result[i])\n",
    "        seg_dict['PPG']['units'] = None\n",
    "        \n",
    "        seg_dict['label'] = label\n",
    "        \n",
    "        save_filename = test_sub + '_' + str(i).zfill(3) + '.npy'\n",
    "        save_path = save_prefix + save_filename\n",
    "        np.save(save_path, seg_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f987494-8891-49a3-afcf-708092c7e6f6",
   "metadata": {},
   "source": [
    "- label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a17424b7-8a7b-4f56-b7b4-6893fe8a519a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    85\n",
       "1    26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npy_paths = glob.glob('../00_Data/04_Stress_Classification/02_val/*.npy')\n",
    "npy_labels = []\n",
    "\n",
    "for path in npy_paths:\n",
    "    data_dict = np.load(path, allow_pickle=True).item()\n",
    "    npy_labels.append(data_dict['label'])\n",
    "    \n",
    "pd.Series(npy_labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62e81ed-c08b-4a60-8970-4926a0020917",
   "metadata": {},
   "source": [
    "## make partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c656cf71-df8d-4e40-ad36-45a297172dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215b4f97-70ab-46eb-96ab-64db28bd2ae3",
   "metadata": {},
   "source": [
    "- load train, val, test paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89e2b5c4-7b93-4738-8549-fd095a033420",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = glob.glob('../00_Data/04_Stress_Classification/01_train/*.npy')\n",
    "valset = glob.glob('../00_Data/04_Stress_Classification/02_val/*.npy')\n",
    "testset = glob.glob('../00_Data/04_Stress_Classification/03_test/*.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0f43d1-1e4b-4ce4-9430-c7903d59f952",
   "metadata": {},
   "source": [
    "- partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ddf3255-8ed1-439f-9b9d-d51dc2462c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = {}\n",
    "partition['trainset'] = trainset\n",
    "partition['valset'] = valset\n",
    "partition['testset'] = testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48d9aa91-9fd9-4a7b-9e53-b6870550734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./partition/partition_formatting.npy\", partition)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
