{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3205de1-8006-4201-83f4-e7ac7e7ceb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as skp\n",
    "\n",
    "from gan_models import GeneratorResNet\n",
    "from scipy.interpolate import splrep, splev\n",
    "from biosppy.signals import tools as tools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import heartpy as hp\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import neurokit2 as nk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1cc858-eedf-468e-9d42-2711b25d9a8f",
   "metadata": {},
   "source": [
    "- Define Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3fe5828-d008-4979-97fa-5c15e464965b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch Versions: 2.1.1+cu118  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print(\"Using Pytorch Versions:\", torch.__version__, ' Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8407c00a-b02c-43bc-b640-e41fcc9d4ee0",
   "metadata": {},
   "source": [
    "- 필요 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0b44791-527f-4fdc-b60e-530ab4fbadcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_spline(ecg, step=1, k=3):\n",
    "\n",
    "    x_new = np.arange(0, ecg.shape[0], ecg.shape[0]/step)\n",
    "    interp_spline_method = splrep(np.arange(0, ecg.shape[0], 1), ecg, k=k)\n",
    "    return splev(x_new, interp_spline_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94e514fe-189d-40cf-91b7-7c6fb7ca29f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ppg(signal, sampling_rate):\n",
    "    \n",
    "    signal = np.array(signal)\n",
    "    sampling_rate = float(sampling_rate)\n",
    "    filtered, _, _ = tools.filter_signal(signal=signal,\n",
    "                                  ftype='butter',\n",
    "                                  band='bandpass',\n",
    "                                  order=4, #3\n",
    "                                  frequency=[1, 8], #[0.5, 8]\n",
    "                                  sampling_rate=sampling_rate)\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "550f2586-b8e4-4712-b25d-01c7059bd92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hr(peaks, fs=250):\n",
    "    rr_inter = []\n",
    "    tmp = 0\n",
    "    for x in peaks:\n",
    "        if tmp == 0:\n",
    "            tmp = x\n",
    "            continue\n",
    "        rr_inter.append(60 / (abs(x - tmp) / fs))\n",
    "        tmp = x\n",
    "    return np.mean(rr_inter)\n",
    "\n",
    "def calc_ppg_hr(ppg_sig, fs, peak_method='elgendi'):\n",
    "    \"\"\"\n",
    "    method : \"elgendi\", \"bishop\"\n",
    "    \"\"\"\n",
    "    ppg_peak = nk.ppg_findpeaks(ppg_sig, sampling_rate=fs, method=peak_method)['PPG_Peaks']\n",
    "    hr = calc_hr(ppg_peak, fs)\n",
    "    \n",
    "    return hr\n",
    "\n",
    "def calc_ecg_hr(ecg_sig, fs, peak_method='nabian2018'):\n",
    "    \"\"\"\n",
    "    method : \"nabian2018\", \"neurokit\"\n",
    "    \"\"\"\n",
    "    ecg_peak = nk.ecg_peaks(ecg_sig, sampling_rate=fs, method=\"nabian2018\")[1]['ECG_R_Peaks']\n",
    "    hr = calc_hr(ecg_peak, fs)\n",
    "    \n",
    "    return hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5ff54e6-928c-41bc-a260-c98e30b25c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(y, y_pred):\n",
    "    return mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ebb2562-cecb-4032-b419-6c97ea951f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(path):\n",
    "    with open(path,'rb') as file: # Binary read\n",
    "        _data = pickle._Unpickler(file)\n",
    "        _data.encoding = 'latin1'\n",
    "        data = _data.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693f6a31-12f0-47bd-a7fe-2fb26153edc7",
   "metadata": {},
   "source": [
    "- load P2E 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b2f08ba-98df-4422-885f-49ff40d036a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneratorResNet(\n",
       "  (model): Sequential(\n",
       "    (0): ReflectionPad1d((1, 1))\n",
       "    (1): Conv1d(1, 64, kernel_size=(7,), stride=(1,), padding=(1,))\n",
       "    (2): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(2,))\n",
       "    (5): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (7): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(2,))\n",
       "    (8): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (9): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (10): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad1d((1, 1))\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (4): ReflectionPad1d((1, 1))\n",
       "        (5): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (6): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (11): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad1d((1, 1))\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (4): ReflectionPad1d((1, 1))\n",
       "        (5): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (6): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (12): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad1d((1, 1))\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (4): ReflectionPad1d((1, 1))\n",
       "        (5): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (6): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (13): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad1d((1, 1))\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (4): ReflectionPad1d((1, 1))\n",
       "        (5): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (6): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (14): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad1d((1, 1))\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (4): ReflectionPad1d((1, 1))\n",
       "        (5): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (6): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (15): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad1d((1, 1))\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (4): ReflectionPad1d((1, 1))\n",
       "        (5): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (6): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (16): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (17): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (18): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (19): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (20): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (21): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (22): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (23): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (24): ReflectionPad1d((1, 1))\n",
       "    (25): Conv1d(64, 1, kernel_size=(7,), stride=(1,))\n",
       "    (26): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_path = './gan_weights/PPG2ECG_CycleGAN_1Epochs.pth'\n",
    "input_shape = (None, 1, int(128 * 64))\n",
    "n_residual_blocks = 6\n",
    "\n",
    "G_AB = GeneratorResNet(input_shape, n_residual_blocks)\n",
    "weights = torch.load(weights_path)\n",
    "G_AB.load_state_dict(weights['G_AB'])\n",
    "G_AB.to(DEVICE)\n",
    "G_AB.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4dab1c-be95-427e-8c56-5a3f24272b92",
   "metadata": {},
   "source": [
    "- get datapaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46891f48-4607-4378-97ba-4345a44d1bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_paths = glob.glob('../00_Data/01_PPG2ECG/01_Original/03_DaLia/*/*.pkl')\n",
    "gt_paths = [i for i in range(len(sig_paths))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de48b61d-5263-4f1b-9dd6-bf4797088d60",
   "metadata": {},
   "source": [
    "- HR 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aa97683-ff92-4ec3-8ecb-3481e1d6e65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [06:12<00:00, 24.84s/it]\n"
     ]
    }
   ],
   "source": [
    "ppg_origin_sig_fs = 64\n",
    "ecg_origin_sig_fs = 700\n",
    "target_sig_fs = 128\n",
    "window_sec = 8\n",
    "batch_size = 100\n",
    "\n",
    "ppg_window_size = window_sec * ppg_origin_sig_fs\n",
    "ecg_window_size = window_sec * ecg_origin_sig_fs\n",
    "\n",
    "ppg_hr_mae_list = []\n",
    "ecg_hr_mae_list = []\n",
    "for sig_path, gt_path in tqdm(zip(sig_paths, gt_paths), total=len(sig_paths)):\n",
    "    origin_sig = load_pickle(sig_path)\n",
    "#     origin_gt = pd.read_csv(gt_path)\n",
    "    \n",
    "    ppg_sig = origin_sig['signal']['wrist']['BVP'].flatten()\n",
    "    origin_ecg_sig = origin_sig['signal']['chest']['ECG'].flatten()\n",
    "    \n",
    "    # PPG signal process\n",
    "    ppg_sig_processed = []\n",
    "    sig_iters = len(ppg_sig) // ppg_window_size\n",
    "    for i in range(sig_iters):\n",
    "        ppg_seg = ppg_sig[i*ppg_window_size : (i+1)*ppg_window_size]\n",
    "        ppg_seg = interp_spline(ppg_seg, step=target_sig_fs*window_sec, k=5)\n",
    "        ppg_seg = (ppg_seg-ppg_seg.mean()) / (ppg_seg.std() + 1e-17)\n",
    "        ppg_seg = skp.minmax_scale(ppg_seg, (-1, 1), axis=0)\n",
    "        ppg_sig_processed.append(np.expand_dims(ppg_seg, 0))\n",
    "    ppg_sig_processed = np.array(ppg_sig_processed)\n",
    "    \n",
    "    # Origin ECG signal process (do not interpolation)\n",
    "    origin_ecg_sig_processed = []\n",
    "    sig_iters = len(origin_ecg_sig) // ecg_window_size\n",
    "    for i in range(sig_iters):\n",
    "        origin_ecg_seg = origin_ecg_sig[i*ecg_window_size : (i+1)*ecg_window_size]\n",
    "        origin_ecg_seg = (origin_ecg_seg-origin_ecg_seg.mean()) / (origin_ecg_seg.std() + 1e-17)\n",
    "        origin_ecg_seg = skp.minmax_scale(origin_ecg_seg, (-1, 1), axis=0)\n",
    "        origin_ecg_sig_processed.append(np.expand_dims(origin_ecg_seg, 0))\n",
    "    origin_ecg_sig_processed = np.array(origin_ecg_sig_processed)\n",
    "    \n",
    "    # make syn ecg (batch size)\n",
    "    input_ppg_sig = torch.from_numpy(ppg_sig_processed).type(torch.FloatTensor)\n",
    "    syn_ecg_sig = []\n",
    "    \n",
    "    infer_iters = len(input_ppg_sig) // batch_size\n",
    "    for i in range(infer_iters):\n",
    "        batch_input_ppg = input_ppg_sig[i*batch_size : (i+1)*batch_size].to(DEVICE)\n",
    "        batch_syn_ecg = G_AB(batch_input_ppg).data.cpu().numpy()\n",
    "        syn_ecg_sig.extend(batch_syn_ecg)\n",
    "        \n",
    "    syn_ecg_sig = np.array(syn_ecg_sig)\n",
    "    origin_ecg_sig_processed = origin_ecg_sig_processed[:syn_ecg_sig.shape[0]]\n",
    "    ppg_sig_processed = ppg_sig_processed[:syn_ecg_sig.shape[0]]      \n",
    "    \n",
    "    # HR GT process (origin ecg -> HR)\n",
    "    HR_GT_seg = []\n",
    "    for i in range(len(origin_ecg_sig_processed)):\n",
    "        try:\n",
    "            gt_hr = calc_ecg_hr(origin_ecg_sig_processed[i][0], fs=ecg_origin_sig_fs)\n",
    "            HR_GT_seg.append(gt_hr)\n",
    "        except:\n",
    "            HR_GT_seg.append(np.NaN)\n",
    "    HR_GT_seg = np.array(HR_GT_seg)\n",
    "        \n",
    "    # inference PPG HR\n",
    "    ppg_infer_hr = []\n",
    "    for i in range(len(ppg_sig_processed)):\n",
    "        try:\n",
    "            ppg_hr = calc_ppg_hr(ppg_sig_processed[i][0], fs=target_sig_fs)\n",
    "            ppg_infer_hr.append(ppg_hr)\n",
    "        except:\n",
    "            ppg_infer_hr.append(np.NaN)\n",
    "    ppg_infer_hr = np.array(ppg_infer_hr)\n",
    "    \n",
    "    # inference SYNECG HR\n",
    "    ecg_infer_hr = []\n",
    "    for i in range(len(ppg_sig_processed)):\n",
    "        try:\n",
    "            ecg_hr = calc_ppg_hr(syn_ecg_sig[i][0], fs=target_sig_fs)\n",
    "            ecg_infer_hr.append(ecg_hr)\n",
    "        except:\n",
    "            ecg_infer_hr.append(np.NaN)\n",
    "    ecg_infer_hr = np.array(ecg_infer_hr)\n",
    "        \n",
    "    # calculate MAE (NaN 제거)\n",
    "    if np.isnan(HR_GT_seg.sum()) or np.isnan(ppg_infer_hr.sum()) or np.isnan(ecg_infer_hr.sum()):\n",
    "        except_index = np.argwhere(np.isnan(HR_GT_seg)).flatten()\n",
    "        HR_GT_seg = np.delete(HR_GT_seg, except_index)\n",
    "        ppg_infer_hr = np.delete(ppg_infer_hr, except_index)\n",
    "        ecg_infer_hr = np.delete(ecg_infer_hr, except_index)\n",
    "        \n",
    "        except_index = np.argwhere(np.isnan(ppg_infer_hr)).flatten()\n",
    "        HR_GT_seg = np.delete(HR_GT_seg, except_index)\n",
    "        ppg_infer_hr = np.delete(ppg_infer_hr, except_index)\n",
    "        ecg_infer_hr = np.delete(ecg_infer_hr, except_index)\n",
    "        \n",
    "        except_index = np.argwhere(np.isnan(ecg_infer_hr)).flatten()\n",
    "        HR_GT_seg = np.delete(HR_GT_seg, except_index)\n",
    "        ppg_infer_hr = np.delete(ppg_infer_hr, except_index)\n",
    "        ecg_infer_hr = np.delete(ecg_infer_hr, except_index)\n",
    "            \n",
    "    ppg_mae = MAE(HR_GT_seg, ppg_infer_hr)\n",
    "    ecg_mae = MAE(HR_GT_seg, ecg_infer_hr)\n",
    "\n",
    "    ppg_hr_mae_list.append(ppg_mae)\n",
    "    ecg_hr_mae_list.append(ecg_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4ab6d-e31f-4770-8517-0f448705e301",
   "metadata": {},
   "source": [
    "- PPG 오차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d632282-8706-40c4-b402-c3d65ba4d1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.367306995578003"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ppg_hr_mae_list).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261cae85-478b-4ac6-b68a-c08136d57582",
   "metadata": {},
   "source": [
    "- SYNECG 오차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d45b4c85-d1c1-4bf6-b43f-a0019e09fd79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.77471890791821"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ecg_hr_mae_list).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
