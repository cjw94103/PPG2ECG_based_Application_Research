{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "525b08b7-4aea-418c-9a60-a988bdadce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn.preprocessing as skp\n",
    "\n",
    "from gan_models import GeneratorResNet\n",
    "from scipy.interpolate import splrep, splev\n",
    "from biosppy.signals import tools as tools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import heartpy as hp\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import neurokit2 as nk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe763b0-572e-4f49-b36e-f614188851db",
   "metadata": {},
   "source": [
    "- Define Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b938b41-7007-41d7-9313-d7021e9a7a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch Versions: 2.1.1+cu118  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print(\"Using Pytorch Versions:\", torch.__version__, ' Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc5554e-33cb-4d37-810e-607ccf3ca848",
   "metadata": {},
   "source": [
    "- 필요 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e433567e-753e-422d-aeb1-b7323b246f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_spline(ecg, step=1, k=3):\n",
    "\n",
    "    x_new = np.arange(0, ecg.shape[0], ecg.shape[0]/step)\n",
    "    interp_spline_method = splrep(np.arange(0, ecg.shape[0], 1), ecg, k=k)\n",
    "    return splev(x_new, interp_spline_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93163ff9-f10e-4b5f-a1f1-ccbf49e8c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ppg(signal, sampling_rate):\n",
    "    \n",
    "    signal = np.array(signal)\n",
    "    sampling_rate = float(sampling_rate)\n",
    "    filtered, _, _ = tools.filter_signal(signal=signal,\n",
    "                                  ftype='butter',\n",
    "                                  band='bandpass',\n",
    "                                  order=4, #3\n",
    "                                  frequency=[1, 8], #[0.5, 8]\n",
    "                                  sampling_rate=sampling_rate)\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9de32da6-ea8b-4b3e-b9d9-0efc7382daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hr(peaks, fs=250):\n",
    "    rr_inter = []\n",
    "    tmp = 0\n",
    "    for x in peaks:\n",
    "        if tmp == 0:\n",
    "            tmp = x\n",
    "            continue\n",
    "        rr_inter.append(60 / (abs(x - tmp) / fs))\n",
    "        tmp = x\n",
    "    return np.mean(rr_inter)\n",
    "\n",
    "def calc_ppg_hr(ppg_sig, fs, peak_method='elgendi'):\n",
    "    \"\"\"\n",
    "    method : \"elgendi\", \"bishop\"\n",
    "    \"\"\"\n",
    "    ppg_peak = nk.ppg_findpeaks(ppg_sig, sampling_rate=fs, method=peak_method)['PPG_Peaks']\n",
    "    hr = calc_hr(ppg_peak, fs)\n",
    "    \n",
    "    return hr\n",
    "\n",
    "def calc_ecg_hr(ecg_sig, fs, peak_method='nabian2018'):\n",
    "    \"\"\"\n",
    "    method : \"nabian2018\", \"neurokit\"\n",
    "    \"\"\"\n",
    "    ecg_peak = nk.ecg_peaks(ecg_sig, sampling_rate=fs, method=\"nabian2018\")[1]['ECG_R_Peaks']\n",
    "    hr = calc_hr(ecg_peak, fs)\n",
    "    \n",
    "    return hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df1eb9cc-f57c-4e71-a13a-9910f0b4a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(y, y_pred):\n",
    "    return mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8474fea7-c0e8-4743-afb5-80e6efd1831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(path):\n",
    "    with open(path,'rb') as file: # Binary read\n",
    "        _data = pickle._Unpickler(file)\n",
    "        _data.encoding = 'latin1'\n",
    "        data = _data.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c34e6-1f03-4836-9fe3-cec212511377",
   "metadata": {},
   "source": [
    "- load P2E model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16271c0b-c458-4d5c-a3ce-fe8ff9a7923d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneratorResNet(\n",
       "  (model): Sequential(\n",
       "    (0): ReflectionPad1d((1, 1))\n",
       "    (1): Conv1d(1, 64, kernel_size=(7,), stride=(1,), padding=(1,))\n",
       "    (2): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(2,))\n",
       "    (5): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (7): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(2,))\n",
       "    (8): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (9): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (10): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad1d((1, 1))\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (4): ReflectionPad1d((1, 1))\n",
       "        (5): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (6): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (11): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad1d((1, 1))\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (4): ReflectionPad1d((1, 1))\n",
       "        (5): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (6): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (12): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad1d((1, 1))\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (4): ReflectionPad1d((1, 1))\n",
       "        (5): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (6): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (13): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad1d((1, 1))\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (4): ReflectionPad1d((1, 1))\n",
       "        (5): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (6): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (14): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad1d((1, 1))\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (4): ReflectionPad1d((1, 1))\n",
       "        (5): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (6): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (15): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad1d((1, 1))\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (4): ReflectionPad1d((1, 1))\n",
       "        (5): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "        (6): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (16): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (17): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (18): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (19): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (20): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (21): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (22): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (23): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (24): ReflectionPad1d((1, 1))\n",
       "    (25): Conv1d(64, 1, kernel_size=(7,), stride=(1,))\n",
       "    (26): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_path = './gan_weights/PPG2ECG_CycleGAN_1Epochs.pth'\n",
    "input_shape = (None, 1, int(128 * 64))\n",
    "n_residual_blocks = 6\n",
    "\n",
    "G_AB = GeneratorResNet(input_shape, n_residual_blocks)\n",
    "weights = torch.load(weights_path)\n",
    "G_AB.load_state_dict(weights['G_AB'])\n",
    "G_AB.to(DEVICE)\n",
    "G_AB.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269f60d5-a248-4332-8a95-8a28cc749793",
   "metadata": {},
   "source": [
    "- get datapaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf98750d-8713-4785-94d5-e139f0b948ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_paths = glob.glob('../00_Data/01_PPG2ECG/01_Original/04_WESAD/*/*.pkl')\n",
    "gt_paths = [i for i in range(len(sig_paths))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb54bf18-4367-4d7f-8a11-f31f78343813",
   "metadata": {},
   "source": [
    "- HR 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d997bab-2c19-4008-b46b-3fd767fcb624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [04:12<00:00, 16.84s/it]\n"
     ]
    }
   ],
   "source": [
    "ppg_origin_sig_fs = 64\n",
    "ecg_origin_sig_fs = 700\n",
    "target_sig_fs = 128\n",
    "window_sec = 8\n",
    "batch_size = 100\n",
    "\n",
    "ppg_window_size = window_sec * ppg_origin_sig_fs\n",
    "ecg_window_size = window_sec * ecg_origin_sig_fs\n",
    "\n",
    "ppg_hr_mae_list = []\n",
    "ecg_hr_mae_list = []\n",
    "for sig_path, gt_path in tqdm(zip(sig_paths, gt_paths), total=len(sig_paths)):\n",
    "    origin_sig = load_pickle(sig_path)\n",
    "#     origin_gt = pd.read_csv(gt_path)\n",
    "    \n",
    "    ppg_sig = origin_sig['signal']['wrist']['BVP'].flatten()\n",
    "    origin_ecg_sig = origin_sig['signal']['chest']['ECG'].flatten()\n",
    "    \n",
    "    # PPG signal process\n",
    "    ppg_sig_processed = []\n",
    "    sig_iters = len(ppg_sig) // ppg_window_size\n",
    "    for i in range(sig_iters):\n",
    "        ppg_seg = ppg_sig[i*ppg_window_size : (i+1)*ppg_window_size]\n",
    "        ppg_seg = interp_spline(ppg_seg, step=target_sig_fs*window_sec, k=5)\n",
    "        ppg_seg = (ppg_seg-ppg_seg.mean()) / (ppg_seg.std() + 1e-17)\n",
    "        ppg_seg = skp.minmax_scale(ppg_seg, (-1, 1), axis=0)\n",
    "        ppg_sig_processed.append(np.expand_dims(ppg_seg, 0))\n",
    "    ppg_sig_processed = np.array(ppg_sig_processed)\n",
    "    \n",
    "    # Origin ECG signal process (do not interpolation)\n",
    "    origin_ecg_sig_processed = []\n",
    "    sig_iters = len(origin_ecg_sig) // ecg_window_size\n",
    "    for i in range(sig_iters):\n",
    "        origin_ecg_seg = origin_ecg_sig[i*ecg_window_size : (i+1)*ecg_window_size]\n",
    "        origin_ecg_seg = (origin_ecg_seg-origin_ecg_seg.mean()) / (origin_ecg_seg.std() + 1e-17)\n",
    "        origin_ecg_seg = skp.minmax_scale(origin_ecg_seg, (-1, 1), axis=0)\n",
    "        origin_ecg_sig_processed.append(np.expand_dims(origin_ecg_seg, 0))\n",
    "    origin_ecg_sig_processed = np.array(origin_ecg_sig_processed)\n",
    "    \n",
    "    # make syn ecg (batch size)\n",
    "    input_ppg_sig = torch.from_numpy(ppg_sig_processed).type(torch.FloatTensor)\n",
    "    syn_ecg_sig = []\n",
    "    \n",
    "    infer_iters = len(input_ppg_sig) // batch_size\n",
    "    for i in range(infer_iters):\n",
    "        batch_input_ppg = input_ppg_sig[i*batch_size : (i+1)*batch_size].to(DEVICE)\n",
    "        batch_syn_ecg = G_AB(batch_input_ppg).data.cpu().numpy()\n",
    "        syn_ecg_sig.extend(batch_syn_ecg)\n",
    "        \n",
    "    syn_ecg_sig = np.array(syn_ecg_sig)\n",
    "    origin_ecg_sig_processed = origin_ecg_sig_processed[:syn_ecg_sig.shape[0]]\n",
    "    ppg_sig_processed = ppg_sig_processed[:syn_ecg_sig.shape[0]]      \n",
    "    \n",
    "    # HR GT process (origin ecg -> HR)\n",
    "    HR_GT_seg = []\n",
    "    for i in range(len(origin_ecg_sig_processed)):\n",
    "        try:\n",
    "            gt_hr = calc_ecg_hr(origin_ecg_sig_processed[i][0], fs=ecg_origin_sig_fs)\n",
    "            HR_GT_seg.append(gt_hr)\n",
    "        except:\n",
    "            HR_GT_seg.append(np.NaN)\n",
    "    HR_GT_seg = np.array(HR_GT_seg)\n",
    "        \n",
    "    # inference PPG HR\n",
    "    ppg_infer_hr = []\n",
    "    for i in range(len(ppg_sig_processed)):\n",
    "        try:\n",
    "            ppg_hr = calc_ppg_hr(ppg_sig_processed[i][0], fs=target_sig_fs)\n",
    "            ppg_infer_hr.append(ppg_hr)\n",
    "        except:\n",
    "            ppg_infer_hr.append(np.NaN)\n",
    "    ppg_infer_hr = np.array(ppg_infer_hr)\n",
    "    \n",
    "    # inference SYNECG HR\n",
    "    ecg_infer_hr = []\n",
    "    for i in range(len(ppg_sig_processed)):\n",
    "        try:\n",
    "            ecg_hr = calc_ppg_hr(syn_ecg_sig[i][0], fs=target_sig_fs)\n",
    "            ecg_infer_hr.append(ecg_hr)\n",
    "        except:\n",
    "            ecg_infer_hr.append(np.NaN)\n",
    "    ecg_infer_hr = np.array(ecg_infer_hr)\n",
    "        \n",
    "    # calculate MAE (NaN 제거)\n",
    "    if np.isnan(HR_GT_seg.sum()) or np.isnan(ppg_infer_hr.sum()) or np.isnan(ecg_infer_hr.sum()):\n",
    "        except_index = np.argwhere(np.isnan(HR_GT_seg)).flatten()\n",
    "        HR_GT_seg = np.delete(HR_GT_seg, except_index)\n",
    "        ppg_infer_hr = np.delete(ppg_infer_hr, except_index)\n",
    "        ecg_infer_hr = np.delete(ecg_infer_hr, except_index)\n",
    "        \n",
    "        except_index = np.argwhere(np.isnan(ppg_infer_hr)).flatten()\n",
    "        HR_GT_seg = np.delete(HR_GT_seg, except_index)\n",
    "        ppg_infer_hr = np.delete(ppg_infer_hr, except_index)\n",
    "        ecg_infer_hr = np.delete(ecg_infer_hr, except_index)\n",
    "        \n",
    "        except_index = np.argwhere(np.isnan(ecg_infer_hr)).flatten()\n",
    "        HR_GT_seg = np.delete(HR_GT_seg, except_index)\n",
    "        ppg_infer_hr = np.delete(ppg_infer_hr, except_index)\n",
    "        ecg_infer_hr = np.delete(ecg_infer_hr, except_index)\n",
    "            \n",
    "    ppg_mae = MAE(HR_GT_seg, ppg_infer_hr)\n",
    "    ecg_mae = MAE(HR_GT_seg, ecg_infer_hr)\n",
    "\n",
    "    ppg_hr_mae_list.append(ppg_mae)\n",
    "    ecg_hr_mae_list.append(ecg_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d7b55-6514-49c0-ba4e-f2170acde405",
   "metadata": {},
   "source": [
    "- PPG HR 오차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d2a38a9-4ae3-4154-8e45-8193491e5315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.86353078954456"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ppg_hr_mae_list).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9fb529-3ae2-4205-b375-5fe40698a58b",
   "metadata": {},
   "source": [
    "- SYNECG HR 오차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c43fe67e-8d9b-4af5-a07e-f234a8288cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.428658128403312"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ecg_hr_mae_list).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
