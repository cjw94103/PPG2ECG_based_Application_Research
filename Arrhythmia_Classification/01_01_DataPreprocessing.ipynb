{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3bf7257-0a37-48ce-ad70-9febc64bccc3",
   "metadata": {},
   "source": [
    "- 각 파일당 환자 1명의 레코드로 취급\n",
    "- train:val:test = 6:2:2로 split 수행\n",
    "- train, val, test split 수행 시 각 환자 단위로 split되야하고 각 환자는 여러 label을 가지고 있으므로 label 분포 비교를 여러번 수행하여 train, val, test의 label 비율이 동일하도록 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cd1946-907c-4a56-b2e2-448b9610c17e",
   "metadata": {},
   "source": [
    "## 01. Train, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f44c8378-d2be-4741-9001-1cc67c6a4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import scipy.io as io\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b701c4-9377-42c9-83ed-33730206418e",
   "metadata": {},
   "source": [
    "- 레이블 분포 비교를 위한 KLDivergence 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9185b060-e67e-40c6-9155-908e881c5f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(p, q):\n",
    "    return np.sum(np.where(p != 0, p * np.log(p / q), 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730a4d31-d3e9-44c0-93a9-d552ca1ff7bc",
   "metadata": {},
   "source": [
    "- load data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef0b129a-53ea-458d-81b2-b9c17d277f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = glob.glob('../00_Data/02_Arrhythmia_Classification/01_Original/*.mat')\n",
    "\n",
    "all_labels = []\n",
    "for path in data_paths:\n",
    "    data = io.loadmat(path)\n",
    "    all_labels.extend(data['labels'].flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6824a0ba-13c9-43d2-90b8-9a9d9f575a2d",
   "metadata": {},
   "source": [
    "- 부정맥 레이블 분포 산출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c169cfd5-2fe7-4559-bd92-49fba7d6c969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31187136, 0.09449676, 0.08057317, 0.04653298, 0.12123348,\n",
       "       0.34529225])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dist = (pd.Series(all_labels).value_counts().sort_index() / pd.Series(all_labels).value_counts().sum()).values\n",
    "all_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2196422-6de0-415a-aa05-c16ec00ab1f5",
   "metadata": {},
   "source": [
    "- seed를 변경해가며 테스트해서 Train, Test 세트의 분포를 전체 부정맥 레이블과 동일하게 근사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b0750e6-6dd9-4cad-9fcd-524b1de38cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [03:45<00:00,  2.26s/it]\n"
     ]
    }
   ],
   "source": [
    "seed_list = []\n",
    "kl_dist = []\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    random_seed = np.random.randint(0, 10000000)\n",
    "    trainset, testset,_ , _ = train_test_split(data_paths, data_paths, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "    train_class = []\n",
    "    test_class = []\n",
    "\n",
    "    for path in trainset:\n",
    "        data = io.loadmat(path)\n",
    "        train_class.extend(data['labels'].flatten())\n",
    "\n",
    "    for path in testset:\n",
    "        data = io.loadmat(path)\n",
    "        test_class.extend(data['labels'].flatten())\n",
    "        \n",
    "    train_dist = (pd.Series(train_class).value_counts().sort_index() / pd.Series(train_class).value_counts().sum()).values\n",
    "    test_dist = (pd.Series(test_class).value_counts().sort_index() / pd.Series(test_class).value_counts().sum()).values\n",
    "    \n",
    "    kld = kl_divergence(train_dist, test_dist)\n",
    "    seed_list.append(random_seed)\n",
    "    kl_dist.append(kld)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbdd75d-236e-4122-b07b-c51830c003b5",
   "metadata": {},
   "source": [
    "- 가장 유사한 train, test 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94180125-0fec-4c25-bc00-96d88f33d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = seed_list[np.argsort(kl_dist)[0]]\n",
    "trainset, testset,_ , _ = train_test_split(data_paths, data_paths, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "train_class = []\n",
    "test_class = []\n",
    "\n",
    "for path in trainset:\n",
    "    data = io.loadmat(path)\n",
    "    train_class.extend(data['labels'].flatten())\n",
    "\n",
    "for path in testset:\n",
    "    data = io.loadmat(path)\n",
    "    test_class.extend(data['labels'].flatten())\n",
    "\n",
    "train_dist = (pd.Series(train_class).value_counts().sort_index() / pd.Series(train_class).value_counts().sum()).values\n",
    "test_dist = (pd.Series(test_class).value_counts().sort_index() / pd.Series(test_class).value_counts().sum()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "261d2749-5464-4172-8a83-9b5f74779fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31749546, 0.09465372, 0.07805997, 0.04500587, 0.12247892,\n",
       "       0.34230605])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bf9c587-5f96-4a4e-8453-bd50ab7d8cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2893075 , 0.09386707, 0.09065611, 0.05265975, 0.11623675,\n",
       "       0.35727282])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d7d3d5-df58-426c-a2db-e62d04f73e09",
   "metadata": {},
   "source": [
    "- 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85c70614-65e7-48d2-bf52-121e165f4635",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_traintest = {}\n",
    "partition_traintest['trainset'] = trainset\n",
    "partition_traintest['testset'] = testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35c16147-5f25-467f-9a46-974822b6f4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 19)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(partition_traintest['trainset']),len(partition_traintest['testset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6340da2e-288b-473f-ad61-7319ded7f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./partition/01_partition_traintest.npy',  partition_traintest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61996366-d684-48e8-a01e-70e3febffd39",
   "metadata": {},
   "source": [
    "## 02. Train, Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea8472c5-b930-4e15-94e2-5ec8c2309dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import scipy.io as io\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeda972-1910-4c0d-a2a2-15b7bff0f4f7",
   "metadata": {},
   "source": [
    "- KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9771a9c3-d851-4604-b48e-4e6a84fbb081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(p, q):\n",
    "    return np.sum(np.where(p != 0, p * np.log(p / q), 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec83d9b7-49b7-4bc0-b97d-d5b7e00846d6",
   "metadata": {},
   "source": [
    "- load partition_traintest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67785b3b-8178-443e-9dbe-7979ccd202df",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = np.load('./partition/01_partition_traintest.npy', allow_pickle=True).item()\n",
    "\n",
    "origin_trainset = partition['trainset']\n",
    "\n",
    "all_labels = []\n",
    "for path in origin_trainset:\n",
    "    data = io.loadmat(path)\n",
    "    all_labels.extend(data['labels'].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "743d7892-98d1-4d6a-bf14-c74aaf7a8f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dist = (pd.Series(all_labels).value_counts().sort_index() / pd.Series(all_labels).value_counts().sum()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdfdd186-04fc-41f4-a5a8-2ad8981af2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31749546, 0.09465372, 0.07805997, 0.04500587, 0.12247892,\n",
       "       0.34230605])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e568a8f3-8e2a-4821-9af6-b8296e82c1f4",
   "metadata": {},
   "source": [
    "- search best seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7214c4d1-084a-4238-ae15-f2502b70550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:58<00:00,  1.79s/it]\n"
     ]
    }
   ],
   "source": [
    "seed_list = []\n",
    "kl_dist = []\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    random_seed = np.random.randint(0, 10000000)\n",
    "    trainset, valset,_ , _ = train_test_split(origin_trainset, origin_trainset, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "    train_class = []\n",
    "    val_class = []\n",
    "\n",
    "    for path in trainset:\n",
    "        data = io.loadmat(path)\n",
    "        train_class.extend(data['labels'].flatten())\n",
    "\n",
    "    for path in valset:\n",
    "        data = io.loadmat(path)\n",
    "        val_class.extend(data['labels'].flatten())\n",
    "        \n",
    "    train_dist = (pd.Series(train_class).value_counts().sort_index() / pd.Series(train_class).value_counts().sum()).values\n",
    "    val_dist = (pd.Series(val_class).value_counts().sort_index() / pd.Series(val_class).value_counts().sum()).values\n",
    "    \n",
    "    kld = kl_divergence(train_dist, val_dist)\n",
    "    seed_list.append(random_seed)\n",
    "    kl_dist.append(kld)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3135188-16b8-498f-b0ba-d1811638d47b",
   "metadata": {},
   "source": [
    "- 가장 유사한 train, val 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b8a01bf-ed5c-493e-8f5f-97ceb1547e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = seed_list[np.argsort(kl_dist)[0]]\n",
    "trainset, valset,_ , _ = train_test_split(origin_trainset, origin_trainset, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "train_class = []\n",
    "val_class = []\n",
    "\n",
    "for path in trainset:\n",
    "    data = io.loadmat(path)\n",
    "    train_class.extend(data['labels'].flatten())\n",
    "\n",
    "for path in valset:\n",
    "    data = io.loadmat(path)\n",
    "    val_class.extend(data['labels'].flatten())\n",
    "\n",
    "train_dist = (pd.Series(train_class).value_counts().sort_index() / pd.Series(train_class).value_counts().sum()).values\n",
    "val_dist = (pd.Series(val_class).value_counts().sort_index() / pd.Series(val_class).value_counts().sum()).values\n",
    "\n",
    "kld = kl_divergence(train_dist, val_dist)\n",
    "seed_list.append(random_seed)\n",
    "kl_dist.append(kld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79307571-4d48-47c0-b8b8-46483e98b6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32380383, 0.09406647, 0.07444301, 0.04834479, 0.12564332,\n",
       "       0.33369858])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d58738d5-c149-4c3d-bbcf-662353772d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29170626, 0.09705443, 0.09284648, 0.03135605, 0.10954255,\n",
       "       0.37749423])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dd6e00d-f93f-4a30-9538-0aca80d951b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31749546, 0.09465372, 0.07805997, 0.04500587, 0.12247892,\n",
       "       0.34230605])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6778ee-1303-4849-a98f-61465961db3c",
   "metadata": {},
   "source": [
    "- make train, val, test partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c66e3218-5511-497f-bbfd-322526d39bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_trainval_test = {}\n",
    "partition_trainval_test['trainset'] = trainset\n",
    "partition_trainval_test['valset'] = valset\n",
    "partition_trainval_test['testset'] = partition['testset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c6d3b88-14ed-49b0-9f64-d994d43d8d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 15, 19)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(partition_trainval_test['trainset']), len(partition_trainval_test['valset']), len(partition_trainval_test['testset'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b57c18-fb80-44f5-b537-441700bc3f82",
   "metadata": {},
   "source": [
    "- save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3c5bbc1-5e32-43fa-b852-417f031da0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./partition/02_partition_trainval_test.npy', partition_trainval_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4a453a-7218-4ecc-9241-a515a58aa997",
   "metadata": {},
   "source": [
    "## 3. Convert npy file\n",
    "- 01, 02에서 작업한 train, val, test 파일을 npy 파일로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d270a2d-a92d-44f4-89a1-3bc53ff9b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as io\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec1421f-96be-4053-81e0-08a140221277",
   "metadata": {},
   "source": [
    "- 필요 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f8a46f3-6c25-45f2-baf8-5149ee032857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_dict(PPG_sig, PPG_fs, PPG_units, label):\n",
    "    # make ecg dict\n",
    "    ecg_dict = None\n",
    "    \n",
    "    # make ppg dict\n",
    "    ppg_dict = {}\n",
    "    ppg_dict['sig'] = PPG_sig\n",
    "    ppg_dict['sig_fs'] = PPG_fs\n",
    "    ppg_dict['sig_time'] = len(PPG_sig) // PPG_fs # seconds\n",
    "    ppg_dict['sig_len'] = len(PPG_sig)\n",
    "    ppg_dict['units'] = PPG_units\n",
    "    ppg_dict['label'] = label\n",
    "    \n",
    "    # make personal info\n",
    "    person_info = None\n",
    "    \n",
    "    # make final data_dict\n",
    "    data_dict = {}\n",
    "    data_dict['ECG'] = ecg_dict\n",
    "    data_dict['PPG'] = ppg_dict\n",
    "    data_dict['Personal_Info'] = person_info\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdb9f16-fb41-481f-87de-4f10cde6fc76",
   "metadata": {},
   "source": [
    "- load partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d02778-6b78-4cf5-a97e-21235861108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = np.load('./partition/02_partition_trainval_test.npy', allow_pickle=True).item()\n",
    "\n",
    "trainset = partition['trainset']\n",
    "valset = partition['valset']\n",
    "testset = partition['testset']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a405cc-4ebd-4146-8a23-039156336262",
   "metadata": {},
   "source": [
    "- trainset 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a99d7f0-0304-4766-958c-10ecc989c973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:30<00:00,  1.86it/s]\n"
     ]
    }
   ],
   "source": [
    "save_prefix = '../00_Data/02_Arrhythmia_Classification/02_Formatting/01_train/'\n",
    "\n",
    "for path in tqdm(trainset, total=len(trainset)):\n",
    "    original_data = io.loadmat(path)\n",
    "    \n",
    "    original_ppg_signal = original_data['ppgseg']\n",
    "    label = original_data['labels']\n",
    "    \n",
    "    ppg_sig_fs = 100\n",
    "    ppg_units = None\n",
    "    \n",
    "    for i in range(len(original_ppg_signal)):\n",
    "        seg_ppg = np.transpose(original_ppg_signal[i:i+1], (1, 0))[:,0]\n",
    "        seg_dict = make_data_dict(seg_ppg, ppg_sig_fs, ppg_units, label[i][0])\n",
    "        \n",
    "        save_filename = path.split('\\\\')[-1].split('.')[0] + '_' + str(i+1).zfill(4) + '.npy'\n",
    "        save_path = save_prefix + save_filename\n",
    "        \n",
    "        np.save(save_path, seg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee32937b-c64e-4d1a-bc8a-d35edbf11a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30117"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob('../00_Data/02_Arrhythmia_Classification/02_Formatting/01_train/*.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c057099a-669c-4c41-8798-279248ed2e1f",
   "metadata": {},
   "source": [
    "- valset 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "008d01d2-2ef3-440f-af38-b915cff29e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:07<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "save_prefix = '../00_Data/02_Arrhythmia_Classification/02_Formatting/02_val/'\n",
    "\n",
    "for path in tqdm(valset, total=len(valset)):\n",
    "    original_data = io.loadmat(path)\n",
    "    \n",
    "    original_ppg_signal = original_data['ppgseg']\n",
    "    label = original_data['labels']\n",
    "    \n",
    "    ppg_sig_fs = 100\n",
    "    ppg_units = None\n",
    "    \n",
    "    for i in range(len(original_ppg_signal)):\n",
    "        seg_ppg = np.transpose(original_ppg_signal[i:i+1], (1, 0))[:,0]\n",
    "        seg_dict = make_data_dict(seg_ppg, ppg_sig_fs, ppg_units, label[i][0])\n",
    "        \n",
    "        save_filename = path.split('\\\\')[-1].split('.')[0] + '_' + str(i+1).zfill(4) + '.npy'\n",
    "        save_path = save_prefix + save_filename\n",
    "        \n",
    "        np.save(save_path, seg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d79ebab-a68c-4f49-97a0-333f4973df86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7367"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob('../00_Data/02_Arrhythmia_Classification/02_Formatting/02_val/*.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c7f4ca-dfe7-4875-9711-cfd4b7d4992b",
   "metadata": {},
   "source": [
    "- testset 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccbc7b2d-87d1-41be-8a29-4c0580a299db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:09<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "save_prefix = '../00_Data/02_Arrhythmia_Classification/02_Formatting/03_test/'\n",
    "\n",
    "for path in tqdm(testset, total=len(testset)):\n",
    "    original_data = io.loadmat(path)\n",
    "    \n",
    "    original_ppg_signal = original_data['ppgseg']\n",
    "    label = original_data['labels']\n",
    "    \n",
    "    ppg_sig_fs = 100\n",
    "    ppg_units = None\n",
    "    \n",
    "    for i in range(len(original_ppg_signal)):\n",
    "        seg_ppg = np.transpose(original_ppg_signal[i:i+1], (1, 0))[:,0]\n",
    "        seg_dict = make_data_dict(seg_ppg, ppg_sig_fs, ppg_units, label[i][0])\n",
    "        \n",
    "        save_filename = path.split('\\\\')[-1].split('.')[0] + '_' + str(i+1).zfill(4) + '.npy'\n",
    "        save_path = save_prefix + save_filename\n",
    "        \n",
    "        np.save(save_path, seg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3550ba28-619b-4fd5-9d32-84bb4cfc043a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9343"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob('../00_Data/02_Arrhythmia_Classification/02_Formatting/03_test/*.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f1297-2ece-411d-a2ca-daef7db95c96",
   "metadata": {},
   "source": [
    "- partition_formatting 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b6de0f5-65e6-41ba-a772-e403af0a94ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5322d87d-66fc-46e9-a94a-2a52075131bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = glob.glob('../00_Data/02_Arrhythmia_Classification/02_Formatting/01_train/*.npy')\n",
    "valset = glob.glob('../00_Data/02_Arrhythmia_Classification/02_Formatting/02_val/*.npy')\n",
    "testset = glob.glob('../00_Data/02_Arrhythmia_Classification/02_Formatting/03_test//*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc823628-d4ca-4e74-b54b-ad508279a479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30117, 7367, 9343)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset), len(valset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6fc7cf7-7a32-4c01-bf80-7c1ec0ad3457",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_formatting = {}\n",
    "partition_formatting['trainset'] = trainset\n",
    "partition_formatting['valset'] = valset\n",
    "partition_formatting['testset'] = testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21b32535-29e3-4489-aa1b-e7535e38ce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./partition/03_partition_formatting.npy', partition_formatting)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
